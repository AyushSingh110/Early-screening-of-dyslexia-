{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e023ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (154, 7)\n",
      "y shape: (154,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load(\"../data/language/processed/X_features.npy\")\n",
    "y = np.load(\"../data/language/processed/y_labels.npy\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52d17b",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efecc61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (115, 7)\n",
      "Test: (39, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8ea33",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f8f9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Language Model)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        39\n",
      "   macro avg       1.00      1.00      1.00        39\n",
      "weighted avg       1.00      1.00      1.00        39\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 1  0]\n",
      " [ 0 38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Classification Report (Language Model)\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44cb4768",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Requesting 2-fold cross-validation but provided less than 2 examples for at least one class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      4\u001b[0m base_model \u001b[38;5;241m=\u001b[39m LogisticRegression(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      6\u001b[0m calibrated_model \u001b[38;5;241m=\u001b[39m CalibratedClassifierCV(\n\u001b[0;32m      7\u001b[0m     base_model,\n\u001b[0;32m      8\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# Platt scaling\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[43mcalibrated_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\dyslexia_env\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\dyslexia_env\\lib\\site-packages\\sklearn\\calibration.py:408\u001b[0m, in \u001b[0;36mCalibratedClassifierCV.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    406\u001b[0m     n_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_folds \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39munique(y, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m n_folds):\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequesting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-fold \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross-validation but provided less than \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples for at least one class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, LeaveOneOut):\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLeaveOneOut cross-validation does not allow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall classes to be present in test splits. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use a cross-validation generator that allows \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall classes to appear in every test and train split.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Requesting 2-fold cross-validation but provided less than 2 examples for at least one class."
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_model = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "\n",
    "calibrated_model = CalibratedClassifierCV(\n",
    "    base_model,\n",
    "    method=\"sigmoid\",   # Platt scaling\n",
    "    cv=2\n",
    ")\n",
    "\n",
    "calibrated_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41567067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a135c28",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e453f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.97      1.00      0.99        38\n",
      "\n",
      "    accuracy                           0.97        39\n",
      "   macro avg       0.49      0.50      0.49        39\n",
      "weighted avg       0.95      0.97      0.96        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\dyslexia_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\dyslexia_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\dyslexia_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Results\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be56a4d",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1f0777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        39\n",
      "   macro avg       1.00      1.00      1.00        39\n",
      "weighted avg       1.00      1.00      1.00        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Results\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644e18dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Logistic Regression)\n",
      "[[ 1  0]\n",
      " [ 0 38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix (Logistic Regression)\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "#Proves no normal detected , Everything flagged dyslexic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45380d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated recall: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\dyslexia_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Using stratified cross validation \n",
    "#Using stratified k-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "recalls = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\"\n",
    "    )\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    recalls.append(recall_score(y_te, y_pred))\n",
    "\n",
    "print(\"Cross-validated recall:\", sum(recalls)/len(recalls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e40ef",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba3f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spelling_error_rate      : 0.0037\n",
      "non_word_ratio           : 0.0037\n",
      "phonetic_error_ratio     : 0.0000\n",
      "repetition_score         : 0.0000\n",
      "avg_word_length          : 0.0041\n",
      "word_count               : -0.0060\n",
      "rare_word_ratio          : 0.0037\n"
     ]
    }
   ],
   "source": [
    "feature_names = [\n",
    "    \"spelling_error_rate\",\n",
    "    \"non_word_ratio\",\n",
    "    \"phonetic_error_ratio\",\n",
    "    \"repetition_score\",\n",
    "    \"avg_word_length\",\n",
    "    \"word_count\",\n",
    "    \"rare_word_ratio\"\n",
    "]\n",
    "\n",
    "for name, coef in zip(feature_names, lr.coef_[0]):\n",
    "    print(f\"{name:25s}: {coef:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4a0969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language risk model saved\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(lr, \"../models/language_risk_model.pkl\")\n",
    "print(\"Language risk model saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043eca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455c411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da310805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d286d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab38e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyslexia_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
